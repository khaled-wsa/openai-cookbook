{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMf801UQomJDu0CaIjPAenm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khaled-wsa/openai-cookbook/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "QliX4Bfi5Jvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rapidsai-community/rapidsai-csp-utils.git"
      ],
      "metadata": {
        "id": "Cy_k66e25y_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bash rapidsai-csp-utils/colab/rapids-colab.sh\n",
        "import sys, os \n"
      ],
      "metadata": {
        "id": "V5_cDKoL56FQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bash /content/rapidsai-csp-utils/colab/rapids-colab.sh\n",
        "import sys, os"
      ],
      "metadata": {
        "id": "HGDKhGtB7MSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This will update the Colab environment and restart the kernel.\n",
        "!bash rapidsai-csp-utils/colab/update_gcc.sh\n",
        "import os\n",
        "os._exit(00)"
      ],
      "metadata": {
        "id": "91CgBudn7Pyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Installing CondaColab.  This will restart your kernel again\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "id": "vrzLwEmM7S2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import condacolab\n",
        "condacolab.check()"
      ],
      "metadata": {
        "id": "sQnhascQ7Vbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # Installing RAPIDS is now 'python rapidsai-csp-utils/colab/install_rapids.py <release> <packages>'\n",
        "    # The <release> options are 'stable' and 'nightly'.  Leaving it blank or adding any other words will default to stable.\n",
        "    # The <packages> option are default blank or 'core'.  By default, we install RAPIDSAI and BlazingSQL.  The 'core' option will install only RAPIDSAI and not include BlazingSQL, \n",
        "    !python rapidsai-csp-utils/colab/install_rapids.py nightly\n",
        "    import os\n",
        "    os.environ['NUMBAPRO_NVVM'] = '/usr/local/cuda/nvvm/lib64/libnvvm.so'\n",
        "    os.environ['NUMBAPRO_LIBDEVICE'] = '/usr/local/cuda/nvvm/libdevice/'\n",
        "    os.environ['CONDA_PREFIX'] = '/usr/local'"
      ],
      "metadata": {
        "id": "03mztvnC7aOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install scikit-learn\n",
        "!pip install joblib\n",
        "!pip install cudf-cu11 dask-cudf-cu11 --extra-index-url=https://pypi.nvidia.com\n",
        "!pip install cuml-cu11 --extra-index-url=https://pypi.nvidia.com\n",
        "!pip install cugraph-cu11 --extra-index-url=https://pypi.nvidia.com\n"
      ],
      "metadata": {
        "id": "G4ad29c01ZpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "sw5y4K6MJRde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "from cuml.cluster import KMeans as KMeansGPU\n",
        "\n",
        "# Constants\n",
        "INITIAL_CAPITAL = 10000\n",
        "TARGET_GAIN = 2.0\n",
        "BEST_MODEL_FILE = \"best_model.pkl\"\n",
        "\n",
        "def load_data(file_path):\n",
        "    data = pd.read_csv(file_path, delimiter=\"\\t\")\n",
        "    data[\"datetime\"] = pd.to_datetime(data[\"<DATE>\"] + \" \" + data[\"<TIME>\"])\n",
        "    data.set_index(\"datetime\", inplace=True)\n",
        "    data[\"returns\"] = data[\"<CLOSE>\"].pct_change()\n",
        "    data.dropna(inplace=True)\n",
        "    return data\n",
        "\n",
        "def split_data(data):\n",
        "    return train_test_split(data, test_size=0.2, shuffle=False)\n",
        "\n",
        "def preprocess_data(train_data, test_data):\n",
        "    scaler = StandardScaler()\n",
        "    train_features = scaler.fit_transform(train_data[[\"<CLOSE>\", \"returns\"]])\n",
        "    test_features = scaler.transform(test_data[[\"<CLOSE>\", \"returns\"]])\n",
        "    return train_features, test_features\n",
        "\n",
        "def create_model(train_features, n_clusters):\n",
        "    kmeans = KMeansGPU(n_clusters=n_clusters, n_init=10)\n",
        "    kmeans.fit(train_features)\n",
        "    return kmeans\n",
        "\n",
        "def trading_strategy_with_position_sizing(data, initial_capital):\n",
        "    position = 0\n",
        "    units = 0\n",
        "    capital = initial_capital\n",
        "    pnl = []\n",
        "\n",
        "    for index, row in data.iterrows():\n",
        "        if row[\"cluster\"] == 0 and position == 0:\n",
        "            position = 1\n",
        "            units = capital // row[\"<CLOSE>\"]\n",
        "            capital -= units * row[\"<CLOSE>\"]\n",
        "        elif row[\"cluster\"] == 1 and position == 1:\n",
        "            position = 0\n",
        "            capital += units * row[\"<CLOSE>\"]\n",
        "            units = 0\n",
        "\n",
        "        pnl.append(units * row[\"returns\"])\n",
        "\n",
        "    return pnl, capital\n",
        "\n",
        "def find_best_strategy(train_features, test_features, test_data, initial_capital, target_gain):\n",
        "    best_gain = 0\n",
        "    best_parameters = None\n",
        "    best_model = None\n",
        "    best_pnl = None\n",
        "\n",
        "    for n_clusters in range(2, 11):\n",
        "        kmeans = create_model(train_features, n_clusters)\n",
        "        test_data[\"cluster\"] = kmeans.predict(test_features)\n",
        "\n",
        "        pnl, remaining_capital = trading_strategy_with_position_sizing(test_data, initial_capital)\n",
        "        gain = (remaining_capital - initial_capital) / initial_capital\n",
        "\n",
        "        print(f\"Trying n_clusters={n_clusters}, gain={gain:.2%}\")\n",
        "\n",
        "        if gain > best_gain:\n",
        "            best_gain = gain\n",
        "            best_parameters = n_clusters\n",
        "            best_model = kmeans\n",
        "            best_pnl = pnl\n",
        "\n",
        "            # Save the best model\n",
        "            joblib.dump(best_model, BEST_MODEL_FILE)\n",
        "\n",
        "    # Iteratively reinvest the profits until the target gain is reached\n",
        "    current_gain = best_gain\n",
        "    current_capital = initial_capital\n",
        "    while current_gain < target_gain:\n",
        "        current_capital += sum(best_pnl)\n",
        "        pnl, remaining_capital = trading_strategy_with_position_sizing(test_data, current_capital)\n",
        "        current_gain = (remaining_capital - initial_capital) / initial_capital\n",
        "\n",
        "    return best_parameters, current_gain\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    data = load_data(\"XAUUSD.csv\")\n",
        "    train_data, test_data = split_data(data)\n",
        "    train_features, test_features = preprocess_data(train_data, test_data)\n",
        "\n",
        "    best_parameters, best_gain = find_best_strategy(train_features, test_features, test_data, INITIAL_CAPITAL, TARGET_GAIN)\n",
        "    print(\"Best parameters:\", best_parameters)\n",
        "    print(\"Best gain:\", best_gain)\n",
        "\n",
        "    best_model = joblib.load(BEST_MODEL_FILE)\n"
      ],
      "metadata": {
        "id": "Ilov_pda2iDE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}